{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "HiFi-GAN (Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis) ‚Äî —ç—Ç–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–æ–∫–æ–¥–µ—Ä–∞, —Å–ø–æ—Å–æ–±–Ω–∞—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ—á—å –∏–∑ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏. –î–∞–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –ø–æ–ª–Ω—É—é —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é HiFi-GAN, –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ RUSLAN."
      ],
      "metadata": {
        "id": "-PwakDlMy2Q8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "hifi-gan-ruslan/\n",
        "‚îú‚îÄ‚îÄ üìì notebook.ipynb                    # –ü–æ–ª–Ω—ã–π –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è\n",
        "‚îú‚îÄ‚îÄ üìÅ checkpoints/                       # –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ generator_best.pt                 # –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å (val loss 0.231)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_005.pt                  # –≠–ø–æ—Ö–∞ 5\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_010.pt                  # –≠–ø–æ—Ö–∞ 10\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ ...                 \n",
        "‚îú‚îÄ‚îÄ üìÅ output/                             # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ epoch_005/                         # –ü—Ä–∏–º–µ—Ä—ã –Ω–∞ 5 —ç–ø–æ—Ö–µ\n",
        "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0_real.wav\n",
        "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 0_fake.wav\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ epoch_010/                          # –ü—Ä–∏–º–µ—Ä—ã –Ω–∞ 10 —ç–ø–æ—Ö–µ\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "‚îÇ       \n",
        "‚îú‚îÄ‚îÄ üìÅ tensorboard/                        # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ events.out.tfevents.*\n",
        "‚îî‚îÄ‚îÄ üìÅ data/                               # –î–∞—Ç–∞—Å–µ—Ç\n",
        "    ‚îú‚îÄ‚îÄ audio/                             # 5000 wav —Ñ–∞–π–ª–æ–≤\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ 000001.wav\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îú‚îÄ‚îÄ transcriptions/                     # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏\n",
        "    ‚îÇ   ‚îú‚îÄ‚îÄ 000001.txt\n",
        "    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îî‚îÄ‚îÄ custom_dir_index.json               # –ò–Ω–¥–µ–∫—Å –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "```"
      ],
      "metadata": {
        "id": "WZzfM7sQySHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uALlQ9Dmun-1"
      },
      "outputs": [],
      "source": [
        "#  –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# –ü–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(\"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìÅ –î–ê–¢–ê–°–ï–¢ RUSLAN\n",
        "\n",
        "### –û –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
        "\n",
        "**RUSLAN** (Russian Speech Language corpus) ‚Äî —ç—Ç–æ –æ—Ç–∫—Ä—ã—Ç—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è text-to-speech —Å–∏—Å—Ç–µ–º. –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–∏ –¥–∏–∫—Ç–æ—Ä–∞, —á–∏—Ç–∞—é—â–µ–≥–æ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n",
        "\n",
        "**–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞:**\n",
        "- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤**: 22,200\n",
        "- **–û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: ~24 —á–∞—Å–∞\n",
        "- **–ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏**: 44.1 kHz (–∏—Å—Ö–æ–¥–Ω–∞—è), —Ä–µ—Å–µ–º–ø–ª–∏–Ω–≥ –¥–æ 22.05 kHz\n",
        "- **–§–æ—Ä–º–∞—Ç**: WAV, 16-bit PCM\n",
        "- **–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏**: –¢–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–∞–∂–¥–æ–º—É –∞—É–¥–∏–æ\n",
        "- **–Ø–∑—ã–∫**: –†—É—Å—Å–∫–∏–π\n",
        "- **–î–∏–∫—Ç–æ—Ä**: –ñ–µ–Ω—Å–∫–∏–π –≥–æ–ª–æ—Å\n",
        "\n",
        "### –°—Å—ã–ª–∫–∞ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç\n",
        "\n",
        "–î–∞—Ç–∞—Å–µ—Ç RUSLAN –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ Kaggle:\n",
        "\n",
        "üîó **[RUSLAN Dataset on Kaggle](https://www.kaggle.com/datasets/freezerainml/ruslan)**\n",
        "\n",
        "–ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è:\n",
        "```url\n",
        "https://www.kaggle.com/datasets/freezerainml/ruslan\n",
        "```\n",
        "\n",
        "\n",
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "* –ü–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç –∏–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:\n",
        "\n",
        "```\n",
        "ruslan/\n",
        "‚îú‚îÄ‚îÄ ruslan_dataset/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ 000001.wav\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ 000002.wav\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ ...\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ 022200.wav\n",
        "‚îî‚îÄ‚îÄ metadata_RUSLAN_22200.csv\n",
        "```\n",
        "\n",
        "–§–∞–π–ª metadata_RUSLAN_22200.csv —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞–º–∏ –∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n",
        "```\n",
        "000001|–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è —Ñ–∞–π–ª–∞ 000001\n",
        "000002|–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –¥–ª—è —Ñ–∞–π–ª–∞ 000002\n",
        "...\n",
        "```\n",
        "\n",
        "–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –≤ Kaggle Notebook\n",
        "\n",
        "–ü—Ä–∏ —Ä–∞–±–æ—Ç–µ –≤ Kaggle Notebook –¥–∞—Ç–∞—Å–µ—Ç –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã:\n",
        "\n",
        "1. –û—Ç–∫—Ä–æ–π—Ç–µ Kaggle Notebook\n",
        "\n",
        "2. –í –ø—Ä–∞–≤–æ–π –ø–∞–Ω–µ–ª–∏ –Ω–∞–∂–º–∏—Ç–µ \"+ Add Data\"\n",
        "\n",
        "3. –í –ø–æ–∏—Å–∫–µ –≤–≤–µ–¥–∏—Ç–µ \"ruslan\"\n",
        "\n",
        "4. –í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç \"RUSLAN\"\n",
        "\n",
        "–î–∞—Ç–∞—Å–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–º–æ–Ω—Ç–∏—Ä—É–µ—Ç—Å—è –≤ /kaggle/input/ruslan/"
      ],
      "metadata": {
        "id": "4NOMMG190DnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# –ë–õ–û–ö 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê\n",
        "\n",
        "\n",
        "print(\"–ë–õ–û–ö 1: –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–¢–ê–°–ï–¢–ê\")\n",
        "\n",
        "import io\n",
        "import json\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 1. –ü–û–ò–°–ö –ò–°–•–û–î–ù–´–• –î–ê–ù–ù–´–•\n",
        "\n",
        "print(\"\\n–ü–û–ò–°–ö –ò–°–•–û–î–ù–´–• –î–ê–ù–ù–´–•:\")\n",
        "\n",
        "# –ü—É—Ç–∏ –∫ –∏—Å—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º (read-only)\n",
        "SRC_PATHS = [\n",
        "    Path('/kaggle/input/datasets/freezerainml/ruslan'),\n",
        "    Path('/kaggle/input/ruslan'),\n",
        "]\n",
        "\n",
        "src_dir = None\n",
        "for p in SRC_PATHS:\n",
        "    if p.exists():\n",
        "        print(f\"  –ù–∞–π–¥–µ–Ω–æ: {p}\")\n",
        "        src_dir = p\n",
        "        break\n",
        "\n",
        "if src_dir is None:\n",
        "    print(\"  RUSLAN –Ω–µ –Ω–∞–π–¥–µ–Ω!\")\n",
        "    print(\"\\n–ü–æ–¥–∫–ª—é—á–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –≤ –ø—Ä–∞–≤–æ–π –ø–∞–Ω–µ–ª–∏:\")\n",
        "    print(\"  1. –ù–∞–∂–º–∏—Ç–µ '+ Add data'\")\n",
        "    print(\"  2. –ù–∞–π–¥–∏—Ç–µ 'ruslan' –∏–ª–∏ 'RUSLAN Corpus'\")\n",
        "    print(\"  3. –î–æ–±–∞–≤—å—Ç–µ –≤ notebook\")\n",
        "    raise FileNotFoundError(\"RUSLAN dataset not found\")\n",
        "\n",
        "\n",
        "# 2. –¶–ï–õ–ï–í–ê–Ø –î–ò–†–ï–ö–¢–û–†–ò–Ø (writable)\n",
        "\n",
        "print(\"\\n–ü–û–î–ì–û–¢–û–í–ö–ê –¶–ï–õ–ï–í–û–ô –î–ò–†–ï–ö–¢–û–†–ò–ò:\")\n",
        "\n",
        "# –ö–æ–ø–∏—Ä—É–µ–º –≤ working (writable!)\n",
        "out_dir = Path('/kaggle/working/data/ruslan')\n",
        "audio_dir = out_dir / 'audio'\n",
        "text_dir = out_dir / 'transcriptions'\n",
        "\n",
        "if out_dir.exists():\n",
        "    print(f\"  –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {out_dir}\")\n",
        "    print(f\"  Audio: {audio_dir.exists()}\")\n",
        "    print(f\"  Text: {text_dir.exists()}\")\n",
        "else:\n",
        "    print(f\"  –°–æ–∑–¥–∞—ë–º: {out_dir}\")\n",
        "    audio_dir.mkdir(parents=True, exist_ok=True)\n",
        "    text_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "# 3. –ü–û–ò–°–ö WAV –§–ê–ô–õ–û–í –ò –ú–ï–¢–ê–î–ê–ù–ù–´–•\n",
        "\n",
        "print(\"\\n–ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ –ò–°–•–û–î–ù–´–• –î–ê–ù–ù–´–•:\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "src_contents = list(src_dir.iterdir())[:20]\n",
        "print(f\"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ {src_dir}:\")\n",
        "for item in src_contents:\n",
        "    item_type = 'dir' if item.is_dir() else 'file'\n",
        "    print(f\"    - {item.name} ({item_type})\")\n",
        "\n",
        "# –ü–æ–∏—Å–∫ wav —Ñ–∞–π–ª–æ–≤\n",
        "wav_files = list(src_dir.glob('**/*.wav'))\n",
        "print(f\"\\n  –ù–∞–π–¥–µ–Ω–æ wav —Ñ–∞–π–ª–æ–≤: {len(wav_files)}\")\n",
        "\n",
        "# –ü–æ–∏—Å–∫ metadata csv\n",
        "csv_files = list(src_dir.glob('**/*.csv'))\n",
        "print(f\"  –ù–∞–π–¥–µ–Ω–æ csv —Ñ–∞–π–ª–æ–≤: {len(csv_files)}\")\n",
        "\n",
        "# –ü–æ–∏—Å–∫ txt —Ñ–∞–π–ª–æ–≤\n",
        "txt_files = list(src_dir.glob('**/*.txt'))\n",
        "print(f\"  –ù–∞–π–¥–µ–Ω–æ txt —Ñ–∞–π–ª–æ–≤: {len(txt_files)}\")\n",
        "\n",
        "\n",
        "# 4. –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•\n",
        "\n",
        "print(\"\\n–ö–û–ü–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•:\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ —É–∂–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ\n",
        "existing_wavs = list(audio_dir.glob('*.wav'))\n",
        "existing_txts = list(text_dir.glob('*.txt'))\n",
        "\n",
        "if len(existing_wavs) > 0:\n",
        "    print(f\"  –£–∂–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {len(existing_wavs)} wav, {len(existing_txts)} txt\")\n",
        "    print(f\"  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ...\")\n",
        "else:\n",
        "    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö\n",
        "    metadata_csv = src_dir / 'metadata_RUSLAN_22200.csv'\n",
        "\n",
        "    if metadata_csv.exists():\n",
        "        print(f\"  –ù–∞–π–¥–µ–Ω metadata —Ñ–∞–π–ª: {metadata_csv}\")\n",
        "\n",
        "        # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ metadata (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º —Å–∫—Ä–∏–ø—Ç–µ)\n",
        "        wavs_copied = 0\n",
        "        transcriptions_written = 0\n",
        "        skipped = 0\n",
        "\n",
        "        print(\"\\n  –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤...\")\n",
        "\n",
        "        with metadata_csv.open(encoding='utf-8') as f:\n",
        "            for line in tqdm(f, desc=\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ\", total=22200):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                parts = line.split('|', 1)\n",
        "                if len(parts) < 2:\n",
        "                    continue\n",
        "\n",
        "                stem, text = parts[0].strip(), parts[1].strip()\n",
        "                wav_src = src_dir / f'{stem}.wav'\n",
        "\n",
        "                if not wav_src.is_file():\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "\n",
        "                # –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ wav\n",
        "                dest_wav = audio_dir / f'{stem}.wav'\n",
        "                shutil.copy2(wav_src, dest_wav)\n",
        "                wavs_copied += 1\n",
        "\n",
        "                # –ó–∞–ø–∏—Å—å —Ç–µ–∫—Å—Ç–∞\n",
        "                txt_path = text_dir / f'{stem}.txt'\n",
        "                txt_path.write_text(text, encoding='utf-8')\n",
        "                transcriptions_written += 1\n",
        "\n",
        "                # –û–≥—Ä–∞–Ω–∏—á–∏–º –¥–ª—è —Ç–µ—Å—Ç–∞ (—É–±–µ—Ä–∏—Ç–µ –µ—Å–ª–∏ –Ω—É–∂–Ω—ã –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)\n",
        "                if wavs_copied >= 22200:  # ‚Üê –ò–∑–º–µ–Ω–∏—Ç–µ –Ω–∞ 22200 –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "                    print(f\"\\n  –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–∞ {wavs_copied} —Ñ–∞–π–ª–∞—Ö (—Ç–µ—Å—Ç)\")\n",
        "                    break\n",
        "\n",
        "        print(f\"\\n  –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ:\")\n",
        "        print(f\"    Wavs —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {wavs_copied}\")\n",
        "        print(f\"    Transcriptions: {transcriptions_written}\")\n",
        "        print(f\"    –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}\")\n",
        "\n",
        "    else:\n",
        "        # –ï—Å–ª–∏ –Ω–µ—Ç metadata, –∫–æ–ø–∏—Ä—É–µ–º –≤—Å–µ wav —Ñ–∞–π–ª—ã\n",
        "        print(f\"  metadata_RUSLAN_22200.csv –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
        "        print(f\"  –ö–æ–ø–∏—Ä—É–µ–º –≤—Å–µ wav —Ñ–∞–π–ª—ã...\")\n",
        "\n",
        "        limit = 5000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞\n",
        "\n",
        "        for wav_path in tqdm(wav_files[:limit], desc=\"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ\"):\n",
        "            stem = wav_path.stem\n",
        "            dest_wav = audio_dir / f'{stem}.wav'\n",
        "            shutil.copy2(wav_path, dest_wav)\n",
        "\n",
        "            # –°–æ–∑–¥–∞—ë–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è —Ç–µ–∫—Å—Ç–∞\n",
        "            txt_path = text_dir / f'{stem}.txt'\n",
        "            txt_path.write_text('–¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏', encoding='utf-8')\n",
        "\n",
        "        print(f\"  –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ {min(len(wav_files), limit)} —Ñ–∞–π–ª–æ–≤\")\n",
        "\n",
        "\n",
        "# 5. –°–û–ó–î–ê–ù–ò–ï –ò–ù–î–ï–ö–°–ê\n",
        "\n",
        "print(\"\\n–°–û–ó–î–ê–ù–ò–ï –ò–ù–î–ï–ö–°–ê:\")\n",
        "\n",
        "index_path = out_dir / 'custom_dir_index.json'\n",
        "\n",
        "if index_path.exists():\n",
        "    with open(index_path, 'r', encoding='utf-8') as f:\n",
        "        index = json.load(f)\n",
        "    print(f\"  –ó–∞–≥—Ä—É–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å: {len(index)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "else:\n",
        "    index = []\n",
        "    text_files = sorted(list(text_dir.glob('*.txt')))\n",
        "\n",
        "    for txt_path in tqdm(text_files, desc=\"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è\"):\n",
        "        stem = txt_path.stem\n",
        "        wav_path = audio_dir / f'{stem}.wav'\n",
        "\n",
        "        if not wav_path.exists():\n",
        "            continue\n",
        "\n",
        "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read().strip()\n",
        "\n",
        "        index.append({\n",
        "            'path': str(wav_path.resolve()),\n",
        "            'text': text,\n",
        "            'has_audio': True\n",
        "        })\n",
        "\n",
        "    with open(index_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(index, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"  –°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å: {len(index)} –∑–∞–ø–∏—Å–µ–π\")\n",
        "\n",
        "\n",
        "# 6. DATASET CLASS (—Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π)\n",
        "\n",
        "print(\"\\n–°–û–ó–î–ê–ù–ò–ï DATASET:\")\n",
        "\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "class RUSLANDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞\n",
        "    \"\"\"\n",
        "    def __init__(self, index, config, part='train', augment=True):\n",
        "        self.index = index\n",
        "        self.config = config\n",
        "        self.sr = config['sample_rate']\n",
        "        self.segment_size = config['segment_size']\n",
        "        self.part = part\n",
        "        self.augment = augment and (part == 'train')\n",
        "\n",
        "        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/val\n",
        "        random.seed(42)\n",
        "        indices = list(range(len(index)))\n",
        "        random.shuffle(indices)\n",
        "        split_idx = int(0.9 * len(indices))\n",
        "\n",
        "        if part == 'train':\n",
        "            self.indices = indices[:split_idx]\n",
        "        else:\n",
        "            self.indices = indices[split_idx:]\n",
        "\n",
        "        print(f\"  {part}: {len(self.indices)} —Å—ç–º–ø–ª–æ–≤\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def _load_audio(self, path):\n",
        "        try:\n",
        "            audio, sr = sf.read(path)\n",
        "            audio = audio.astype(np.float32)\n",
        "\n",
        "            if len(audio.shape) > 1:\n",
        "                audio = audio[:, 0]\n",
        "\n",
        "            if sr != self.sr:\n",
        "                audio = librosa.resample(audio, orig_sr=sr, target_sr=self.sr)\n",
        "\n",
        "            return audio\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "    def _augment(self, audio):\n",
        "        \"\"\"–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è\"\"\"\n",
        "        if not self.augment:\n",
        "            return audio\n",
        "\n",
        "        aug_type = np.random.randint(0, 4)\n",
        "\n",
        "        if aug_type == 0:\n",
        "            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ ¬±10%\n",
        "            rate = np.random.uniform(0.9, 1.1)\n",
        "            audio = librosa.effects.time_stretch(audio, rate=rate)\n",
        "        elif aug_type == 1:\n",
        "            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∏—Ç—á–∞ ¬±2 –ø–æ–ª—É—Ç–æ–Ω–∞\n",
        "            steps = np.random.uniform(-2, 2)\n",
        "            audio = librosa.effects.pitch_shift(audio, sr=self.sr, n_steps=steps)\n",
        "        elif aug_type == 2:\n",
        "            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞\n",
        "            noise = np.random.randn(len(audio)) * 0.005\n",
        "            audio = audio + noise\n",
        "        elif aug_type == 3:\n",
        "            # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≥—Ä–æ–º–∫–æ—Å—Ç–∏\n",
        "            gain = np.random.uniform(0.8, 1.2)\n",
        "            audio = audio * gain\n",
        "\n",
        "        return audio\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.indices[idx]\n",
        "        item = self.index[real_idx]\n",
        "\n",
        "        audio = self._load_audio(item['path'])\n",
        "\n",
        "        if audio is None or len(audio) < 1000:\n",
        "            audio = np.random.randn(self.segment_size).astype(np.float32) * 0.01\n",
        "        else:\n",
        "            audio = self._augment(audio)\n",
        "\n",
        "            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "            peak = np.max(np.abs(audio))\n",
        "            if peak > 0:\n",
        "                audio = audio / (peak + 1e-7)\n",
        "            audio = np.clip(audio, -1, 1)\n",
        "\n",
        "        # –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç–∞\n",
        "        if len(audio) > self.segment_size:\n",
        "            if self.part == 'train':\n",
        "                start = np.random.randint(0, len(audio) - self.segment_size)\n",
        "            else:\n",
        "                start = 0\n",
        "            audio = audio[start:start + self.segment_size]\n",
        "        else:\n",
        "            audio = np.pad(audio, (0, self.segment_size - len(audio)))\n",
        "\n",
        "        return {\n",
        "            'audio': torch.FloatTensor(audio),\n",
        "            'text': item['text'],\n",
        "            'path': item['path']\n",
        "        }\n",
        "\n",
        "\n",
        "# 7. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –ò DATALOADER\n",
        "\n",
        "config_data = {\n",
        "    'sample_rate': 22050,\n",
        "    'n_mels': 80,\n",
        "    'n_fft': 1024,\n",
        "    'hop_length': 256,\n",
        "    'win_length': 1024,\n",
        "    'f_min': 0,\n",
        "    'f_max': 8000,\n",
        "    'segment_size': 8192,  # –ú–µ–Ω—å—à–µ –¥–ª—è –±–æ–ª—å—à–µ–≥–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è\n",
        "}\n",
        "\n",
        "print(\"\\n–ü–ê–†–ê–ú–ï–¢–†–´:\")\n",
        "for k, v in config_data.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ dataset\n",
        "train_dataset = RUSLANDataset(index, config_data, part='train', augment=True)\n",
        "val_dataset = RUSLANDataset(index, config_data, part='val', augment=False)\n",
        "\n",
        "# Gradient Accumulation –¥–ª—è —ç–º—É–ª—è—Ü–∏–∏ –±–æ–ª—å—à–µ–≥–æ –±–∞—Ç—á–∞\n",
        "batch_size = 4\n",
        "accumulation_steps = 2  # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 8\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=0,  # –°—Ç–∞–±–∏–ª—å–Ω–µ–µ –Ω–∞ Kaggle\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"\\n–°–¢–ê–¢–ò–°–¢–ò–ö–ê:\")\n",
        "print(f\"  Train batches: {len(train_loader)}\")\n",
        "print(f\"  Val batches: {len(val_loader)}\")\n",
        "print(f\"  Effective batch: {batch_size * accumulation_steps}\")\n",
        "print(f\"  Steps per epoch: {len(train_loader) * accumulation_steps}\")\n",
        "\n",
        "\n",
        "# 8. –¢–ï–°–¢–û–í–ê–Ø –ü–†–û–í–ï–†–ö–ê\n",
        "\n",
        "print(\"\\n–¢–ï–°–¢–û–í–ê–Ø –ü–†–û–í–ï–†–ö–ê:\")\n",
        "\n",
        "test_batch = next(iter(train_loader))\n",
        "print(f\"  Audio shape: {test_batch['audio'].shape}\")\n",
        "print(f\"  Audio dtype: {test_batch['audio'].dtype}\")\n",
        "print(f\"  Batch size: {test_batch['audio'].shape[0]}\")\n",
        "print(f\"  Duration: {test_batch['audio'].shape[1] / config_data['sample_rate']:.2f} —Å–µ–∫\")\n"
      ],
      "metadata": {
        "id": "IHBiC4V7utni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ú–û–î–ï–õ–ò\n",
        "\n",
        "### –û–±—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ HiFi-GAN\n",
        "\n",
        "HiFi-GAN —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —Ç—Ä–µ—Ö –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: **–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞**, **–º–Ω–æ–≥–æ–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (MPD)** –∏ **–º–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–≥–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (MSD)**. –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª, –∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—ã –æ—Ü–µ–Ω–∏–≤–∞—é—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–≤—É–∫–∞, —Å—Ä–∞–≤–Ω–∏–≤–∞—è –µ–≥–æ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏.\n"
      ],
      "metadata": {
        "id": "xiFQ8m3I0yOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### 1. –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä (Generator)\n",
        "\n",
        "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤—Ö–æ–¥–Ω—É—é –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—É —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ `[B, 80, T]` –≤ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ `[B, 1, T √ó 256]` (–≥–¥–µ 256 ‚Äî –æ–±—â–∏–π –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø–æ–≤—ã—à–µ–Ω–∏—è —á–∞—Å—Ç–æ—Ç—ã –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏).\n",
        "\n",
        "### 2. –ú–Ω–æ–≥–æ–ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (MPD)\n",
        "MPD –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª, —Ä–∞–∑–¥–µ–ª—è—è –µ–≥–æ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –∫–∞–∂–¥—ã–π –ø–µ—Ä–∏–æ–¥ –æ—Ç–¥–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ 2D —Å–≤–µ—Ä—Ç–∫–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É –≤—ã—è–≤–ª—è—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Ä–µ—á–∏.\n",
        "\n",
        "### 3. –ú–Ω–æ–≥–æ–º–∞—Å—à—Ç–∞–±–Ω—ã–π –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (MSD)\n",
        "MSD –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –º–∞—Å—à—Ç–∞–±–∞—Ö, –ø—Ä–∏–º–µ–Ω—è—è –ø—É–ª–∏–Ω–≥ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —à–∫–∞–ª–æ–π. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É –≤—ã—è–≤–ª—è—Ç—å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ —Ä–µ—á–∏.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9iSXs5kZ1hOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è\n",
        "* MRF (Multi-Receptive Field Fusion): –ü–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã\n",
        "\n",
        "* MPD (Multi-Period Discriminator): –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä —Ä–µ—á–∏\n",
        "\n",
        "* MSD (Multi-Scale Discriminator): –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
        "\n",
        "* Weight Normalization: –°—Ç–∞–±–∏–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
        "\n",
        "* Spectral Normalization: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –ø–µ—Ä–≤–æ–º MSD –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏\n",
        "\n",
        "* LeakyReLU –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—é—Ç \"—É–º–∏—Ä–∞–Ω–∏–µ\" –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
        "\n",
        "* Residual connections: –û–±–ª–µ–≥—á–∞—é—Ç –æ–±—É—á–µ–Ω–∏–µ –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π"
      ],
      "metadata": {
        "id": "GIEd7TBW25a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ë–õ–û–ö 2: –ú–û–î–ï–õ–ò HiFi-GAN\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm, spectral_norm\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# UTILS\n",
        "\n",
        "def _pad(k: int, d: int) -> int:\n",
        "    return (k * d - d) // 2\n",
        "\n",
        "def _init_weights(m, std=0.01):\n",
        "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.ConvTranspose1d)):\n",
        "        nn.init.normal_(m.weight, 0.0, std)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "# MEL SPECTROGRAM\n",
        "\n",
        "class MelSpectrogram(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.sr = config['sample_rate']\n",
        "        self.n_fft = config['n_fft']\n",
        "        self.hop_length = config['hop_length']\n",
        "        self.win_length = config['win_length']\n",
        "        self.n_mels = config['n_mels']\n",
        "        self.f_min = config['f_min']\n",
        "        self.f_max = config['f_max']\n",
        "\n",
        "        mel_basis = librosa.filters.mel(\n",
        "            sr=self.sr,\n",
        "            n_fft=self.n_fft,\n",
        "            n_mels=self.n_mels,\n",
        "            fmin=self.f_min,\n",
        "            fmax=self.f_max\n",
        "        )\n",
        "        self.register_buffer('mel_basis', torch.from_numpy(mel_basis).float())\n",
        "        self.register_buffer('hann_window', torch.hann_window(self.win_length).float())\n",
        "\n",
        "    def forward(self, audio):\n",
        "        spec = torch.stft(\n",
        "            audio,\n",
        "            n_fft=self.n_fft,\n",
        "            hop_length=self.hop_length,\n",
        "            win_length=self.win_length,\n",
        "            window=self.hann_window,\n",
        "            return_complex=True\n",
        "        )\n",
        "        mag = torch.abs(spec)\n",
        "        mel = torch.matmul(self.mel_basis, mag)\n",
        "        mel = torch.log(torch.clamp(mel, min=1e-5))\n",
        "        return mel\n",
        "\n",
        "\n",
        "# GENERATOR\n",
        "\n",
        "class MRFBlock(nn.Module):\n",
        "    def __init__(self, channels, kernel_sizes, dilation_rates):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "            weight_norm(nn.Conv1d(channels, channels, k, dilation=d, padding=_pad(k, d)))\n",
        "            for k in kernel_sizes for d in dilation_rates\n",
        "        ])\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv in self.convs:\n",
        "            x = x + self.act(conv(x))\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.enc_conv = weight_norm(nn.Conv1d(config['n_mels'], config['hidden_dim'], 7, padding=3))\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.mrfs = nn.ModuleList()\n",
        "\n",
        "        for i, (up_rate, kernel_size) in enumerate(zip(\n",
        "            config['upsample_rates'],\n",
        "            config['upsample_kernel_sizes']\n",
        "        )):\n",
        "            in_ch = config['hidden_dim'] // (2 ** i)\n",
        "            out_ch = config['hidden_dim'] // (2 ** (i + 1))\n",
        "\n",
        "            up = nn.ConvTranspose1d(in_ch, out_ch, kernel_size, stride=up_rate, padding=kernel_size//2)\n",
        "            _init_weights(up)\n",
        "            self.ups.append(weight_norm(up))\n",
        "            self.mrfs.append(MRFBlock(out_ch, config['kernel_sizes'], config['dilation_rates']))\n",
        "\n",
        "        self.final_conv = weight_norm(nn.Conv1d(out_ch, 1, 7, padding='same'))\n",
        "        _init_weights(self.final_conv)\n",
        "\n",
        "    def forward(self, mel):\n",
        "        x = self.act(self.enc_conv(mel))\n",
        "\n",
        "        for up, mrf in zip(self.ups, self.mrfs):\n",
        "            x = mrf(up(x))\n",
        "            x = self.act(x)\n",
        "\n",
        "        fake_waveform = torch.tanh(self.final_conv(x))\n",
        "        return fake_waveform\n",
        "\n",
        "\n",
        "# MPD\n",
        "class PeriodDiscriminator(nn.Module):\n",
        "    def __init__(self, period):\n",
        "        super().__init__()\n",
        "        self.period = period\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            weight_norm(nn.Conv2d(1, 64, (5, 1), (3, 1), (2, 0))),\n",
        "            weight_norm(nn.Conv2d(64, 128, (5, 1), (3, 1), (2, 0))),\n",
        "            weight_norm(nn.Conv2d(128, 512, (5, 1), (3, 1), (2, 0))),\n",
        "            weight_norm(nn.Conv2d(512, 1024, (5, 1), (3, 1), (2, 0))),\n",
        "            weight_norm(nn.Conv2d(1024, 1024, (5, 1), (1, 1), (2, 0))),\n",
        "        ])\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "        self.conv = weight_norm(nn.Conv2d(1024, 1, (3, 1), (1, 1), (1, 0)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, T = x.shape\n",
        "        pad = (self.period - T % self.period) % self.period\n",
        "        if pad > 0:\n",
        "            x = F.pad(x, (0, pad), mode='reflect')\n",
        "            T += pad\n",
        "\n",
        "        x = x.view(B, C, T // self.period, self.period)\n",
        "        features = []\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = self.act(conv(x))\n",
        "            features.append(x)\n",
        "\n",
        "        x = self.conv(x)\n",
        "        features.append(x)\n",
        "        return features\n",
        "\n",
        "class MultiPeriodDiscriminator(nn.Module):\n",
        "    def __init__(self, periods=[2, 3, 5, 7, 11]):\n",
        "        super().__init__()\n",
        "        self.discriminators = nn.ModuleList([\n",
        "            PeriodDiscriminator(p) for p in periods\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        for d in self.discriminators:\n",
        "            features.append(d(x))\n",
        "        return features\n",
        "\n",
        "\n",
        "# MSD\n",
        "\n",
        "class ScaleDiscriminator(nn.Module):\n",
        "    def __init__(self, use_spectral_norm=False):\n",
        "        super().__init__()\n",
        "        norm = spectral_norm if use_spectral_norm else weight_norm\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            norm(nn.Conv1d(1, 128, 15, 1, 7)),\n",
        "            norm(nn.Conv1d(128, 128, 41, 2, 20)),\n",
        "            norm(nn.Conv1d(128, 256, 41, 2, 20)),\n",
        "            norm(nn.Conv1d(256, 512, 41, 4, 20)),\n",
        "            norm(nn.Conv1d(512, 1024, 41, 4, 20)),\n",
        "            norm(nn.Conv1d(1024, 1024, 41, 1, 20)),\n",
        "            norm(nn.Conv1d(1024, 1024, 5, 1, 2)),\n",
        "        ])\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "        self.conv = norm(nn.Conv1d(1024, 1, 3, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        for conv in self.convs:\n",
        "            x = self.act(conv(x))\n",
        "            features.append(x)\n",
        "        x = self.conv(x)\n",
        "        features.append(x)\n",
        "        return features\n",
        "\n",
        "class MultiScaleDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.discriminators = nn.ModuleList([\n",
        "            ScaleDiscriminator(True),\n",
        "            ScaleDiscriminator(False),\n",
        "            ScaleDiscriminator(False),\n",
        "        ])\n",
        "        self.avgpools = nn.ModuleList([\n",
        "            nn.Identity(),\n",
        "            nn.AvgPool1d(4, 2, 2),\n",
        "            nn.AvgPool1d(4, 2, 2),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        for avg, d in zip(self.avgpools, self.discriminators):\n",
        "            x = avg(x)\n",
        "            features.append(d(x))\n",
        "        return features\n",
        "\n",
        "\n",
        "# HiFi-GAN COMPLETE\n",
        "\n",
        "class HiFiGAN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(config)\n",
        "        self.mpd = MultiPeriodDiscriminator()\n",
        "        self.msd = MultiScaleDiscriminator()\n",
        "        self.mel_extractor = MelSpectrogram(config)\n",
        "\n",
        "    def forward(self, mel):\n",
        "        return self.generator(mel)\n",
        "\n",
        "    def discriminate(self, fake, real):\n",
        "        fake = fake.detach()\n",
        "        fake_feats = self.mpd(fake) + self.msd(fake)\n",
        "        real_feats = self.mpd(real) + self.msd(real)\n",
        "        return fake_feats, real_feats\n",
        "\n",
        "print(\"\\n–ú–û–î–ï–õ–ò –°–û–ó–î–ê–ù–´:\")\n",
        "print(\"  Generator\")\n",
        "print(\"  MultiPeriodDiscriminator\")\n",
        "print(\"  MultiScaleDiscriminator\")\n",
        "print(\"  MelSpectrogram\")"
      ],
      "metadata": {
        "id": "VhxkEyCMvI16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –û–±–∑–æ—Ä loss —Ñ—É–Ω–∫—Ü–∏–π –≤ HiFi-GAN\n",
        "\n",
        "–í HiFi-GAN –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö loss —Ñ—É–Ω–∫—Ü–∏–π, –∫–∞–∂–¥–∞—è –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∞—Å–ø–µ–∫—Ç –æ–±—É—á–µ–Ω–∏—è. –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è (GAN) —Å —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (feature matching)."
      ],
      "metadata": {
        "id": "IlDQR9QA34sk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### –ö–ª—é—á–µ–≤—ã–µ –≤—ã–≤–æ–¥—ã –æ loss —Ñ—É–Ω–∫—Ü–∏—è—Ö\n",
        "* Feature matching –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–µ–Ω: –ë–µ–∑ –Ω–µ–≥–æ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä \"–∑–∞—Å—ã–ø–∞–µ—Ç\" –∑–∞ 10-15 —ç–ø–æ—Ö\n",
        "\n",
        "* LSGAN —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ BCE: –ö–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ª—É—á—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\n",
        "\n",
        "* Mel loss –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ: –ù–∏–∑–∫–∏–π Mel loss –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –∫–∞—á–µ—Å—Ç–≤–æ–º —Å–∏–Ω—Ç–µ–∑–∞\n",
        "\n",
        "* –ë–∞–ª–∞–Ω—Å –≤–µ—Å–æ–≤ —Ä–µ—à–∞–µ—Ç –≤—Å—ë: Œª_fm=2.0, Œª_mel=45.0 –¥–∞—é—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å\n",
        "\n",
        "* Gradient clipping –Ω–µ–æ–±—Ö–æ–¥–∏–º: –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –≤–∑—Ä—ã–≤—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"
      ],
      "metadata": {
        "id": "1ZoYqw463bQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# –ë–õ–û–ö 3: LOSS –§–£–ù–ö–¶–ò–ò (LSGAN - –°–¢–ê–ë–ò–õ–¨–ù–ï–ï)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"–ë–õ–û–ö 3: LOSS –§–£–ù–ö–¶–ò–ò\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# LSGAN LOSS\n",
        "\n",
        "class GANLoss(nn.Module):\n",
        "    \"\"\"Least Squares GAN - –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã\"\"\"\n",
        "    def __init__(self, is_discriminator=True):\n",
        "        super().__init__()\n",
        "        self.is_disc = is_discriminator\n",
        "\n",
        "    def forward(self, predictions, real_predictions=None):\n",
        "        if self.is_disc:\n",
        "            # Discriminator: E[(D(real)-1)¬≤] + E[D(fake)¬≤]\n",
        "            real_loss = torch.mean((real_predictions - 1.0) ** 2)\n",
        "            fake_loss = torch.mean(predictions ** 2)\n",
        "            return real_loss + fake_loss\n",
        "        else:\n",
        "            # Generator: E[(D(fake)-1)¬≤]\n",
        "            return torch.mean((predictions - 1.0) ** 2)\n",
        "\n",
        "\n",
        "# FEATURE MATCHING LOSS\n",
        "\n",
        "class FeatureMatchingLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = nn.L1Loss()\n",
        "\n",
        "    def forward(self, fake_features, real_features):\n",
        "        loss = 0\n",
        "        for fake_feat_list, real_feat_list in zip(fake_features, real_features):\n",
        "            for fake_feat, real_feat in zip(fake_feat_list, real_feat_list):\n",
        "                # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤\n",
        "                min_len = min(fake_feat.shape[-1], real_feat.shape[-1])\n",
        "                fake_feat = fake_feat[..., :min_len]\n",
        "                real_feat = real_feat[..., :min_len]\n",
        "                loss += self.l1(fake_feat, real_feat)\n",
        "        return loss\n",
        "\n",
        "\n",
        "# COMPLETE HIFI-GAN LOSS\n",
        "\n",
        "class HiFiGANLoss(nn.Module):\n",
        "    def __init__(self, lambda_fm=2.0, lambda_mel=45.0):\n",
        "        super().__init__()\n",
        "        self.lambda_fm = lambda_fm\n",
        "        self.lambda_mel = lambda_mel\n",
        "\n",
        "        self.gan_loss_disc = GANLoss(is_discriminator=True)\n",
        "        self.gan_loss_gen = GANLoss(is_discriminator=False)\n",
        "        self.feature_loss = FeatureMatchingLoss()\n",
        "        self.mel_loss = nn.L1Loss()\n",
        "\n",
        "    def discriminator_loss(self, fake_features, real_features):\n",
        "        \"\"\"Loss –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\"\"\"\n",
        "        total_loss = 0\n",
        "        for fake_feats, real_feats in zip(fake_features, real_features):\n",
        "            total_loss += self.gan_loss_disc(fake_feats[-1], real_feats[-1])\n",
        "        return total_loss\n",
        "\n",
        "    def generator_loss(self, fake_features, real_features, fake_mel, real_mel):\n",
        "        \"\"\"Loss –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (3 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞)\"\"\"\n",
        "        # 1. Adversarial loss\n",
        "        adv_loss = 0\n",
        "        for fake_feats, real_feats in zip(fake_features, real_features):\n",
        "            adv_loss += self.gan_loss_gen(fake_feats[-1])\n",
        "\n",
        "        # 2. Feature matching loss\n",
        "        fm_loss = self.feature_loss(fake_features, real_features)\n",
        "\n",
        "        # 3. Mel spectrogram loss\n",
        "        mel_loss = self.mel_loss(fake_mel, real_mel)\n",
        "\n",
        "        # Weighted sum\n",
        "        total_loss = adv_loss + self.lambda_fm * fm_loss + self.lambda_mel * mel_loss\n",
        "\n",
        "        return {\n",
        "            'total': total_loss,\n",
        "            'adv': adv_loss,\n",
        "            'fm': fm_loss,\n",
        "            'mel': mel_loss\n",
        "        }\n",
        "\n",
        "\n",
        "# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø\n",
        "\n",
        "config = {\n",
        "    'sample_rate': 22050,\n",
        "    'n_mels': 80,\n",
        "    'n_fft': 1024,\n",
        "    'hop_length': 256,\n",
        "    'win_length': 1024,\n",
        "    'f_min': 0,\n",
        "    'f_max': 8000,\n",
        "    'segment_length': 8192,\n",
        "    'generator': {\n",
        "        'n_mels': 80,\n",
        "        'hidden_dim': 512,\n",
        "        'upsample_rates': [8, 8, 2, 2],\n",
        "        'upsample_kernel_sizes': [16, 16, 4, 4],\n",
        "        'kernel_sizes': [3, 7, 11],\n",
        "        'dilation_rates': [1, 3, 5],\n",
        "    },\n",
        "    'training': {\n",
        "        'batch_size': 4,\n",
        "        'accumulation_steps': 2,\n",
        "        'num_epochs': 100,\n",
        "        'lr_generator': 2e-4,\n",
        "        'lr_discriminator': 1e-4,  # D —É—á–∏—Ç—Å—è –º–µ–¥–ª–µ–Ω–Ω–µ–µ!\n",
        "        'beta1': 0.5,  # –ö–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º HiFi-GAN\n",
        "        'beta2': 0.9,\n",
        "        'lambda_fm': 2.0,\n",
        "        'lambda_mel': 45.0,\n",
        "        'gradient_clip': 1.0,\n",
        "        'save_interval': 5,\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n–ü–ê–†–ê–ú–ï–¢–†–´ LOSS:\")\n",
        "print(f\"  Lambda FM: {config['training']['lambda_fm']}\")\n",
        "print(f\"  Lambda Mel: {config['training']['lambda_mel']}\")\n",
        "print(f\"  LR Generator: {config['training']['lr_generator']}\")\n",
        "print(f\"  LR Discriminator: {config['training']['lr_discriminator']}\")\n",
        "print(f\"  Beta1: {config['training']['beta1']} (—Å—Ç–∞–Ω–¥–∞—Ä—Ç GAN)\")"
      ],
      "metadata": {
        "id": "rMST1G8CvdbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  –ë–õ–û–ö 4: –û–ë–£–ß–ï–ù–ò–ï\n",
        "\n",
        "### –û–±–∑–æ—Ä –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "–û–±—É—á–µ–Ω–∏–µ HiFi-GAN ‚Äî —ç—Ç–æ —Å–ª–æ–∂–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –º–µ–∂–¥—É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞–º–∏. –í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –æ–±—ã—á–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π, GAN —Ç—Ä–µ–±—É—é—Ç –æ—Å–æ–±–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –æ–±—É—á–∞—é—Ç—Å—è –ø–æ–æ—á–µ—Ä–µ–¥–Ω–æ –≤ —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –º–∞–Ω–µ—Ä–µ. –í —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–≤–æ–¥–∏–ª–æ—Å—å –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ Kaggle —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU Tesla T4.\n",
        "\n",
        "**–ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:**\n",
        "- **–í—Å–µ–≥–æ —ç–ø–æ—Ö**: 50\n",
        "- **–í—Ä–µ–º—è –Ω–∞ —ç–ø–æ—Ö—É**: ~11 –º–∏–Ω—É—Ç\n",
        "- **–û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è**: ~9 —á–∞—Å–æ–≤\n",
        "- **GPU**: Tesla T4 (16 GB)\n",
        "- **Batch size**: 4 (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π 8 —Å –∞–∫–∫—É–º—É–ª—è—Ü–∏–µ–π)\n",
        "\n",
        "---\n",
        "\n",
        "### 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "```python\n",
        "# –ü–æ–ª–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
        "training_config = {\n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–∞–Ω–Ω—ã—Ö\n",
        "    'batch_size': 4,\n",
        "    'accumulation_steps': 2,      # —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 8\n",
        "    'num_epochs': 50,\n",
        "    'segment_size': 8192,          # –¥–ª–∏–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞ –∞—É–¥–∏–æ –≤ —Å—ç–º–ø–ª–∞—Ö\n",
        "    \n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞\n",
        "    'lr_generator': 2e-4,          # learning rate –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞\n",
        "    'lr_discriminator': 2e-4,      # learning rate –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\n",
        "    'beta1': 0.8,                   # Adam beta1\n",
        "    'beta2': 0.99,                  # Adam beta2\n",
        "    'weight_decay': 0.01,           # L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
        "    \n",
        "    # –í–µ—Å–∞ loss —Ñ—É–Ω–∫—Ü–∏–π\n",
        "    'lambda_fm': 2.0,               # –≤–µ—Å feature matching loss\n",
        "    'lambda_mel': 45.0,             # –≤–µ—Å mel reconstruction loss\n",
        "    \n",
        "    # –°—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—è\n",
        "    'gradient_clip': 1.0,           # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞\n",
        "    'save_interval': 5,              # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö\n",
        "}"
      ],
      "metadata": {
        "id": "BgQ50ntc4LX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ë–õ–û–ö 4: –û–ë–£–ß–ï–ù–ò–ï\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils import weight_norm, spectral_norm, clip_grad_norm_\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 1. –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø\n",
        "\n",
        "mel_config = {\n",
        "    'sample_rate': 22050,\n",
        "    'n_mels': 80,\n",
        "    'n_fft': 1024,\n",
        "    'hop_length': 256,\n",
        "    'win_length': 1024,\n",
        "    'f_min': 0,\n",
        "    'f_max': 8000,\n",
        "}\n",
        "\n",
        "generator_config = {\n",
        "    'n_mels': 80,\n",
        "    'hidden_dim': 512,\n",
        "    'upsample_rates': [8, 8, 2, 2],\n",
        "    'upsample_kernel_sizes': [16, 16, 4, 4],\n",
        "    'kernel_sizes': [3, 7, 11],\n",
        "    'dilation_rates': [1, 3, 5],\n",
        "}\n",
        "\n",
        "training_config = {\n",
        "    'batch_size': 8,\n",
        "    'accumulation_steps': 2,\n",
        "    'num_epochs': 25,\n",
        "    'lr_generator': 2e-4,\n",
        "    'lr_discriminator': 2e-4,\n",
        "    'beta1': 0.8,\n",
        "    'beta2': 0.99,\n",
        "    'weight_decay': 0.01,\n",
        "    'lambda_fm': 2.0,\n",
        "    'lambda_mel': 45.0,\n",
        "    'gradient_clip': 1.0,\n",
        "    'save_interval': 5,\n",
        "}\n",
        "\n",
        "print(\"\\n–ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø:\")\n",
        "for k, v in training_config.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "# 2. –£–°–¢–†–û–ô–°–¢–í–û\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nDevice: {device}\")\n",
        "\n",
        "\n",
        "# 3. –ú–û–î–ï–õ–ò\n",
        "\n",
        "print(\"\\n–°–û–ó–î–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô:\")\n",
        "\n",
        "def _pad(k: int, d: int) -> int:\n",
        "    return (k * d - d) // 2\n",
        "\n",
        "def _init(m, std: float = 0.01):\n",
        "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.ConvTranspose1d, nn.ConvTranspose2d)):\n",
        "        nn.init.normal_(m.weight, 0.0, std)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "\n",
        "# MelSpectrogram\n",
        "\n",
        "class MelSpectrogram(nn.Module):\n",
        "    def __init__(self, config=None):\n",
        "        super().__init__()\n",
        "        if config is None:\n",
        "            config = mel_config\n",
        "        self.sr = config.get('sample_rate', 22050)\n",
        "        self.n_fft = config.get('n_fft', 1024)\n",
        "        self.hop_length = config.get('hop_length', 256)\n",
        "        self.win_length = config.get('win_length', 1024)\n",
        "        self.n_mels = config.get('n_mels', 80)\n",
        "        self.f_min = config.get('f_min', 0)\n",
        "        self.f_max = config.get('f_max', 8000)\n",
        "        self.pad_value = -11.5129251\n",
        "\n",
        "        mel_basis = librosa.filters.mel(\n",
        "            sr=self.sr,\n",
        "            n_fft=self.n_fft,\n",
        "            n_mels=self.n_mels,\n",
        "            fmin=self.f_min,\n",
        "            fmax=self.f_max\n",
        "        )\n",
        "        self.register_buffer('mel_basis', torch.from_numpy(mel_basis).float())\n",
        "        self.register_buffer('hann_window', torch.hann_window(self.win_length).float())\n",
        "\n",
        "    def forward(self, audio):\n",
        "        # audio: [B, T] –∏–ª–∏ [B, 1, T]\n",
        "        if audio.dim() == 3:\n",
        "            audio = audio.squeeze(1)\n",
        "\n",
        "        spec = torch.stft(\n",
        "            audio,\n",
        "            n_fft=self.n_fft,\n",
        "            hop_length=self.hop_length,\n",
        "            win_length=self.win_length,\n",
        "            window=self.hann_window,\n",
        "            return_complex=True\n",
        "        )\n",
        "        mag = torch.abs(spec)\n",
        "        mel = torch.matmul(self.mel_basis, mag)\n",
        "        mel = torch.log(torch.clamp(mel, min=1e-5))\n",
        "        return mel\n",
        "\n",
        "\n",
        "# Generator\n",
        "\n",
        "class MRFBlock(nn.Module):\n",
        "    def __init__(self, channels: int, kr, Dr):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList(\n",
        "            weight_norm(nn.Conv1d(channels, channels, k, dilation=d, padding=_pad(k, d)))\n",
        "            for k in kr for d in Dr\n",
        "        )\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv in self.convs:\n",
        "            x = x + self.act(conv(x))\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        n_mels = config.get('n_mels', 80)\n",
        "        hu = config.get('hidden_dim', 512)\n",
        "        ku = config.get('upsample_kernel_sizes', [16, 16, 4, 4])\n",
        "        kr = config.get('kernel_sizes', [3, 7, 11])\n",
        "        Dr = config.get('dilation_rates', [1, 3, 5])\n",
        "\n",
        "        self.enc_conv = weight_norm(nn.Conv1d(n_mels, hu, 7, padding=3))\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.mrfs = nn.ModuleList()\n",
        "\n",
        "        upsample_rates = config.get('upsample_rates', [8, 8, 2, 2])\n",
        "        for l in range(len(ku)):\n",
        "            in_ch = hu // (2 ** l)\n",
        "            out_ch = hu // (2 ** (l + 1))\n",
        "            up = nn.ConvTranspose1d(in_ch, out_ch, ku[l], stride=upsample_rates[l], padding=ku[l]//2)\n",
        "            _init(up)\n",
        "            self.ups.append(weight_norm(up))\n",
        "            self.mrfs.append(MRFBlock(out_ch, kr, Dr))\n",
        "\n",
        "        final = nn.Conv1d(out_ch, 1, 7, padding='same')\n",
        "        _init(final)\n",
        "        self.final_conv = weight_norm(final)\n",
        "\n",
        "    def forward(self, mel):\n",
        "        x = self.act(self.enc_conv(mel))\n",
        "        for up, mrf in zip(self.ups, self.mrfs):\n",
        "            x = mrf(up(x))\n",
        "            x = self.act(x)\n",
        "        fake_waveform = torch.tanh(self.final_conv(x))\n",
        "        return fake_waveform\n",
        "\n",
        "\n",
        "# MPD\n",
        "\n",
        "class PeriodDiscriminator(nn.Module):\n",
        "    def __init__(self, p: int):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.convs = nn.ModuleList([\n",
        "            weight_norm(nn.Conv2d(1, 64, (5, 1), stride=(3, 1), padding=(2, 0))),\n",
        "            weight_norm(nn.Conv2d(64, 128, (5, 1), stride=(3, 1), padding=(2, 0))),\n",
        "            weight_norm(nn.Conv2d(128, 512, (5, 1), stride=(3, 1), padding=(2, 0))),\n",
        "            weight_norm(nn.Conv2d(512, 1024, (5, 1), stride=(3, 1), padding=(2, 0))),\n",
        "            weight_norm(nn.Conv2d(1024, 1024, (5, 1), padding=(2, 0))),\n",
        "        ])\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "        self.conv = weight_norm(nn.Conv2d(1024, 1, (3, 1), padding=(1, 0)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, 1, T] –∏–ª–∏ [B, T]\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        B, C, T = x.shape\n",
        "        pad = (self.p - T % self.p) % self.p\n",
        "        if pad > 0:\n",
        "            x = F.pad(x, (0, pad), mode=\"reflect\")\n",
        "            T += pad\n",
        "        x = x.view(B, C, T // self.p, self.p)\n",
        "        features = []\n",
        "        for conv in self.convs:\n",
        "            x = self.act(conv(x))\n",
        "            features.append(x)\n",
        "        x = self.conv(x)\n",
        "        features.append(x)\n",
        "        return features\n",
        "\n",
        "class MultiPeriodDiscriminator(nn.Module):\n",
        "    def __init__(self, periods=[2, 3, 5, 7, 11]):\n",
        "        super().__init__()\n",
        "        self.discriminators = nn.ModuleList(PeriodDiscriminator(p) for p in periods)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        features = []\n",
        "        for d in self.discriminators:\n",
        "            features.append(d(x))\n",
        "        return features\n",
        "\n",
        "\n",
        "# MSD\n",
        "\n",
        "class ScaleDiscriminator(nn.Module):\n",
        "    def __init__(self, use_spectral_norm: bool = False):\n",
        "        super().__init__()\n",
        "        norm = spectral_norm if use_spectral_norm else weight_norm\n",
        "        self.convs = nn.ModuleList([\n",
        "            norm(nn.Conv1d(1, 128, 15, stride=1, padding=7)),\n",
        "            norm(nn.Conv1d(128, 128, 41, stride=2, groups=4, padding=20)),\n",
        "            norm(nn.Conv1d(128, 256, 41, stride=2, groups=16, padding=20)),\n",
        "            norm(nn.Conv1d(256, 512, 41, stride=4, groups=16, padding=20)),\n",
        "            norm(nn.Conv1d(512, 1024, 41, stride=4, groups=16, padding=20)),\n",
        "            norm(nn.Conv1d(1024, 1024, 41, stride=1, groups=16, padding=20)),\n",
        "            norm(nn.Conv1d(1024, 1024, 5, stride=1, padding=2)),\n",
        "        ])\n",
        "        self.act = nn.LeakyReLU(0.1)\n",
        "        self.conv = norm(nn.Conv1d(1024, 1, 3, stride=1, padding=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        features = []\n",
        "        for conv in self.convs:\n",
        "            x = self.act(conv(x))\n",
        "            features.append(x)\n",
        "        x = self.conv(x)\n",
        "        features.append(x)\n",
        "        return features\n",
        "\n",
        "class MultiScaleDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.discriminators = nn.ModuleList([\n",
        "            ScaleDiscriminator(use_spectral_norm=True),\n",
        "            ScaleDiscriminator(use_spectral_norm=False),\n",
        "            ScaleDiscriminator(use_spectral_norm=False),\n",
        "        ])\n",
        "        self.avgpools = nn.ModuleList([\n",
        "            nn.Identity(),\n",
        "            nn.AvgPool1d(kernel_size=4, stride=2, padding=2),\n",
        "            nn.AvgPool1d(kernel_size=4, stride=2, padding=2),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        features = []\n",
        "        for avg, d in zip(self.avgpools, self.discriminators):\n",
        "            x = avg(x)\n",
        "            features.append(d(x))\n",
        "        return features\n",
        "\n",
        "\n",
        "# HiFi-GAN\n",
        "\n",
        "class HiFiGAN(nn.Module):\n",
        "    def __init__(self, generator_config):\n",
        "        super().__init__()\n",
        "        self.generator = Generator(generator_config)\n",
        "        self.mpd = MultiPeriodDiscriminator()\n",
        "        self.msd = MultiScaleDiscriminator()\n",
        "\n",
        "    def forward(self, mel):\n",
        "        return self.generator(mel)\n",
        "\n",
        "    def discriminate(self, fake_waveform, audio, train_d=True):\n",
        "        if train_d:\n",
        "            fake_waveform = fake_waveform.detach()\n",
        "\n",
        "        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã\n",
        "        fake_waveform, audio = self.pad_pair(fake_waveform, audio)\n",
        "\n",
        "        period_features_fake = self.mpd(fake_waveform)\n",
        "        period_features_real = self.mpd(audio)\n",
        "        scale_features_fake = self.msd(fake_waveform)\n",
        "        scale_features_real = self.msd(audio)\n",
        "\n",
        "        return {\n",
        "            'mpd_features_fake': period_features_fake,\n",
        "            'mpd_features_real': period_features_real,\n",
        "            'msd_features_fake': scale_features_fake,\n",
        "            'msd_features_real': scale_features_real,\n",
        "        }\n",
        "\n",
        "    def pad_pair(self, a1, a2):\n",
        "        T = max(a1.shape[-1], a2.shape[-1])\n",
        "        p1, p2 = T - a1.shape[-1], T - a2.shape[-1]\n",
        "        if p1 > 0:\n",
        "            a1 = F.pad(a1, (0, p1))\n",
        "        if p2 > 0:\n",
        "            a2 = F.pad(a2, (0, p2))\n",
        "        return a1, a2\n",
        "\n",
        "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
        "model = HiFiGAN(generator_config).to(device)\n",
        "mel_extractor = MelSpectrogram(mel_config).to(device).eval()\n",
        "\n",
        "print(f\"  HiFiGAN (Generator + MPD + MSD)\")\n",
        "print(f\"  MelSpectrogram (–æ—Ç–¥–µ–ª—å–Ω–æ)\")\n",
        "\n",
        "\n",
        "# 4. LOSS –§–£–ù–ö–¶–ò–ò\n",
        "\n",
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, is_disc: bool):\n",
        "        super().__init__()\n",
        "        self.discriminator_mode = is_disc\n",
        "\n",
        "    def forward(self, predictions, ground_truth_predictions=None):\n",
        "        if self.discriminator_mode:\n",
        "            real_sample_loss = torch.mean((ground_truth_predictions - 1.0) ** 2)\n",
        "            fake_sample_loss = torch.mean(predictions ** 2)\n",
        "            return real_sample_loss + fake_sample_loss\n",
        "        else:\n",
        "            return torch.mean((predictions - 1.0) ** 2)\n",
        "\n",
        "class FeatureMatchingLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, generated_feature_pyramid, reference_feature_pyramid):\n",
        "        accumulated_distance = 0.0\n",
        "        for fake_features, real_features in zip(generated_feature_pyramid, reference_feature_pyramid):\n",
        "            for fake_layer, real_layer in zip(fake_features, real_features):\n",
        "                min_len = min(fake_layer.shape[-1], real_layer.shape[-1])\n",
        "                fake_layer = fake_layer[..., :min_len]\n",
        "                real_layer = real_layer[..., :min_len]\n",
        "                accumulated_distance += F.l1_loss(fake_layer, real_layer)\n",
        "        return accumulated_distance\n",
        "\n",
        "class HiFiGANLoss(nn.Module):\n",
        "    def __init__(self, lambda_fm=2.0, lambda_mel=45.0):\n",
        "        super().__init__()\n",
        "        self.adversarial_criterion_disc = GANLoss(is_disc=True)\n",
        "        self.adversarial_criterion_gen = GANLoss(is_disc=False)\n",
        "        self.perceptual_criterion = FeatureMatchingLoss()\n",
        "        self.spectral_criterion = nn.L1Loss()\n",
        "        self.feature_matching_weight = lambda_fm\n",
        "        self.mel_reconstruction_weight = lambda_mel\n",
        "\n",
        "    def discriminator_loss(self, mpd_features_fake, mpd_features_real, msd_features_fake, msd_features_real):\n",
        "        period_critic_loss = sum(\n",
        "            self.adversarial_criterion_disc(fake_pyramid[-1], real_pyramid[-1])\n",
        "            for fake_pyramid, real_pyramid in zip(mpd_features_fake, mpd_features_real)\n",
        "        )\n",
        "        scale_critic_loss = sum(\n",
        "            self.adversarial_criterion_disc(fake_pyramid[-1], real_pyramid[-1])\n",
        "            for fake_pyramid, real_pyramid in zip(msd_features_fake, msd_features_real)\n",
        "        )\n",
        "        return period_critic_loss + scale_critic_loss\n",
        "\n",
        "    def generator_loss(self, mpd_features_fake, mpd_features_real, msd_features_fake, msd_features_real, real_spectrogram, fake_spectrogram):\n",
        "        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º mel-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
        "        min_T = min(real_spectrogram.shape[-1], fake_spectrogram.shape[-1])\n",
        "        real_spectrogram = real_spectrogram[..., :min_T]\n",
        "        fake_spectrogram = fake_spectrogram[..., :min_T]\n",
        "\n",
        "        period_adversarial = sum(\n",
        "            self.adversarial_criterion_gen(fake_pyramid[-1], real_pyramid[-1])\n",
        "            for fake_pyramid, real_pyramid in zip(mpd_features_fake, mpd_features_real)\n",
        "        )\n",
        "        scale_adversarial = sum(\n",
        "            self.adversarial_criterion_gen(fake_pyramid[-1], real_pyramid[-1])\n",
        "            for fake_pyramid, real_pyramid in zip(msd_features_fake, msd_features_real)\n",
        "        )\n",
        "        adversarial_component = period_adversarial + scale_adversarial\n",
        "\n",
        "        period_perceptual = self.perceptual_criterion(mpd_features_fake, mpd_features_real)\n",
        "        scale_perceptual = self.perceptual_criterion(msd_features_fake, msd_features_real)\n",
        "        perceptual_component = period_perceptual + scale_perceptual\n",
        "\n",
        "        spectral_component = self.spectral_criterion(fake_spectrogram, real_spectrogram)\n",
        "\n",
        "        total_generator_loss = (\n",
        "            adversarial_component +\n",
        "            self.feature_matching_weight * perceptual_component +\n",
        "            self.mel_reconstruction_weight * spectral_component\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'total': total_generator_loss,\n",
        "            'adv': adversarial_component,\n",
        "            'fm': perceptual_component,\n",
        "            'mel': spectral_component\n",
        "        }\n",
        "\n",
        "criterion = HiFiGANLoss(\n",
        "    lambda_fm=training_config['lambda_fm'],\n",
        "    lambda_mel=training_config['lambda_mel']\n",
        ").to(device)\n",
        "\n",
        "print(f\"\\nLOSS:\")\n",
        "print(f\"  Lambda FM: {training_config['lambda_fm']}\")\n",
        "print(f\"  Lambda Mel: {training_config['lambda_mel']}\")\n",
        "\n",
        "\n",
        "# 5. –û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–´\n",
        "\n",
        "optimizer_g = torch.optim.AdamW(\n",
        "    model.generator.parameters(),\n",
        "    lr=training_config['lr_generator'],\n",
        "    betas=(training_config['beta1'], training_config['beta2']),\n",
        "    weight_decay=training_config['weight_decay']\n",
        ")\n",
        "\n",
        "optimizer_d = torch.optim.AdamW(\n",
        "    list(model.mpd.parameters()) + list(model.msd.parameters()),\n",
        "    lr=training_config['lr_discriminator'],\n",
        "    betas=(training_config['beta1'], training_config['beta2']),\n",
        "    weight_decay=training_config['weight_decay']\n",
        ")\n",
        "\n",
        "scheduler_g = torch.optim.lr_scheduler.ExponentialLR(optimizer_g, gamma=0.999)\n",
        "scheduler_d = torch.optim.lr_scheduler.ExponentialLR(optimizer_d, gamma=0.999)\n",
        "\n",
        "print(f\"\\n–û–ü–¢–ò–ú–ò–ó–ê–¢–û–†–´:\")\n",
        "print(f\"  Generator: AdamW (lr={training_config['lr_generator']})\")\n",
        "print(f\"  Discriminator: AdamW (lr={training_config['lr_discriminator']})\")\n",
        "\n",
        "\n",
        "# 6. TENSORBOARD –ò –î–ò–†–ï–ö–¢–û–†–ò–ò\n",
        "\n",
        "writer = SummaryWriter(log_dir='/kaggle/working/tensorboard')\n",
        "\n",
        "CHECKPOINT_DIR = Path('/kaggle/working/checkpoints')\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "OUTPUT_DIR = Path('/kaggle/working/output')\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"\\nCheckpoints: {CHECKPOINT_DIR}\")\n",
        "print(f\"Output: {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "# 7. –ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò\n",
        "\n",
        "def count_params(m):\n",
        "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\n–ü–ê–†–ê–ú–ï–¢–†–´:\")\n",
        "print(f\"  Generator: {count_params(model.generator):,}\")\n",
        "print(f\"  MPD: {count_params(model.mpd):,}\")\n",
        "print(f\"  MSD: {count_params(model.msd):,}\")\n",
        "print(f\"  TOTAL: {count_params(model):,}\")\n",
        "\n",
        "\n",
        "# 8. –§–£–ù–ö–¶–ò–ò –û–ë–£–ß–ï–ù–ò–Ø\n",
        "\n",
        "def get_loss_value(loss):\n",
        "    if hasattr(loss, 'item'):\n",
        "        return loss.item()\n",
        "    return float(loss)\n",
        "\n",
        "def train_epoch(epoch):\n",
        "    model.generator.train()\n",
        "    model.mpd.train()\n",
        "    model.msd.train()\n",
        "\n",
        "    losses = {'d': 0, 'g': 0, 'g_adv': 0, 'g_fm': 0, 'g_mel': 0}\n",
        "    batch_count = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    optimizer_d.zero_grad()\n",
        "    optimizer_g.zero_grad()\n",
        "\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        try:\n",
        "            audio = batch['audio'].to(device)  # [B, T]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                real_mel = mel_extractor(audio)\n",
        "\n",
        "            fake_audio = model(real_mel)\n",
        "            fake_mel = mel_extractor(fake_audio)\n",
        "\n",
        "            # DISCRIMINATOR STEP\n",
        "            disc_outputs = model.discriminate(fake_audio, audio, train_d=True)\n",
        "\n",
        "            d_loss = criterion.discriminator_loss(\n",
        "                disc_outputs['mpd_features_fake'],\n",
        "                disc_outputs['mpd_features_real'],\n",
        "                disc_outputs['msd_features_fake'],\n",
        "                disc_outputs['msd_features_real']\n",
        "            )\n",
        "            d_loss = d_loss / training_config['accumulation_steps']\n",
        "            d_loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % training_config['accumulation_steps'] == 0:\n",
        "                clip_grad_norm_(\n",
        "                    list(model.mpd.parameters()) + list(model.msd.parameters()),\n",
        "                    training_config['gradient_clip']\n",
        "                )\n",
        "                optimizer_d.step()\n",
        "                optimizer_d.zero_grad()\n",
        "\n",
        "            # GENERATOR STEP\n",
        "            disc_outputs = model.discriminate(fake_audio, audio, train_d=False)\n",
        "\n",
        "            g_losses = criterion.generator_loss(\n",
        "                disc_outputs['mpd_features_fake'],\n",
        "                disc_outputs['mpd_features_real'],\n",
        "                disc_outputs['msd_features_fake'],\n",
        "                disc_outputs['msd_features_real'],\n",
        "                real_mel,\n",
        "                fake_mel\n",
        "            )\n",
        "            g_loss = g_losses['total'] / training_config['accumulation_steps']\n",
        "            g_loss.backward()\n",
        "\n",
        "            if (batch_idx + 1) % training_config['accumulation_steps'] == 0:\n",
        "                clip_grad_norm_(\n",
        "                    model.generator.parameters(),\n",
        "                    training_config['gradient_clip']\n",
        "                )\n",
        "                optimizer_g.step()\n",
        "                optimizer_g.zero_grad()\n",
        "\n",
        "            # Statistics\n",
        "            losses['d'] += get_loss_value(d_loss) * training_config['accumulation_steps']\n",
        "            losses['g'] += get_loss_value(g_losses['total'])\n",
        "            losses['g_adv'] += get_loss_value(g_losses['adv'])\n",
        "            losses['g_fm'] += get_loss_value(g_losses['fm'])\n",
        "            losses['g_mel'] += get_loss_value(g_losses['mel'])\n",
        "            batch_count += 1\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'D': f\"{get_loss_value(d_loss) * training_config['accumulation_steps']:.3f}\",\n",
        "                'G': f\"{get_loss_value(g_losses['total']):.3f}\"\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n–û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_idx}: {type(e).__name__}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    if batch_count == 0:\n",
        "        raise RuntimeError(\"–ù–∏ –æ–¥–∏–Ω –±–∞—Ç—á –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!\")\n",
        "\n",
        "    for k in losses:\n",
        "        losses[k] /= batch_count\n",
        "\n",
        "    return losses\n",
        "\n",
        "def validate(epoch):\n",
        "    model.generator.eval()\n",
        "    model.mpd.eval()\n",
        "    model.msd.eval()\n",
        "\n",
        "    losses = {'d': 0, 'g_mel': 0}\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validation'):\n",
        "            audio = batch['audio'].to(device)\n",
        "            real_mel = mel_extractor(audio)\n",
        "            fake_audio = model(real_mel)\n",
        "            fake_mel = mel_extractor(fake_audio)\n",
        "\n",
        "            disc_outputs = model.discriminate(fake_audio, audio, train_d=False)\n",
        "            d_loss = criterion.discriminator_loss(\n",
        "                disc_outputs['mpd_features_fake'],\n",
        "                disc_outputs['mpd_features_real'],\n",
        "                disc_outputs['msd_features_fake'],\n",
        "                disc_outputs['msd_features_real']\n",
        "            )\n",
        "\n",
        "            # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º mel –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
        "            min_T = min(real_mel.shape[-1], fake_mel.shape[-1])\n",
        "            g_mel_loss = criterion.spectral_criterion(\n",
        "                fake_mel[..., :min_T],\n",
        "                real_mel[..., :min_T]\n",
        "            )\n",
        "\n",
        "            losses['d'] += get_loss_value(d_loss)\n",
        "            losses['g_mel'] += get_loss_value(g_mel_loss)\n",
        "            batch_count += 1\n",
        "\n",
        "            if batch_count >= 20:\n",
        "                break\n",
        "\n",
        "    if batch_count > 0:\n",
        "        for k in losses:\n",
        "            losses[k] /= batch_count\n",
        "\n",
        "    return losses\n",
        "\n",
        "def save_samples(epoch):\n",
        "    \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ (–ò–°–ü–†–ê–í–õ–ï–ù–û –¥–ª—è soundfile)\"\"\"\n",
        "    model.generator.eval()\n",
        "    sample_dir = OUTPUT_DIR / f'epoch_{epoch:03d}'\n",
        "    sample_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            if i >= 3:\n",
        "                break\n",
        "\n",
        "            audio = batch['audio'][:1].to(device)  # [1, T]\n",
        "            mel = mel_extractor(audio)\n",
        "            fake = model(mel)  # [1, 1, T] –∏–ª–∏ [1, T]\n",
        "\n",
        "            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ –¥–ª—è soundfile\n",
        "            audio_np = audio[0].cpu().numpy()\n",
        "            fake_np = fake[0].cpu().numpy()\n",
        "\n",
        "            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: [1, T] –∏–ª–∏ [1, 1, T] -> [T]\n",
        "            if audio_np.ndim > 1:\n",
        "                audio_np = audio_np.squeeze()\n",
        "            if fake_np.ndim > 1:\n",
        "                fake_np = fake_np.squeeze()\n",
        "\n",
        "            # –ö–ª–∏–ø–ø–∏–Ω–≥ –≤ [-1, 1] –¥–ª—è WAV\n",
        "            audio_np = np.clip(audio_np, -1, 1)\n",
        "            fake_np = np.clip(fake_np, -1, 1)\n",
        "\n",
        "            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ WAV —Å —è–≤–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º\n",
        "            sf.write(\n",
        "                sample_dir / f'{i}_real.wav',\n",
        "                audio_np,\n",
        "                mel_config['sample_rate'],\n",
        "                format='WAV',\n",
        "                subtype='PCM_16'\n",
        "            )\n",
        "            sf.write(\n",
        "                sample_dir / f'{i}_fake.wav',\n",
        "                fake_np,\n",
        "                mel_config['sample_rate'],\n",
        "                format='WAV',\n",
        "                subtype='PCM_16'\n",
        "            )\n",
        "\n",
        "            # TensorBoard (—Ç–∞–∫–∂–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ)\n",
        "            writer.add_audio(f'Real_{i}', audio[0], epoch, mel_config['sample_rate'])\n",
        "            fake_for_tb = fake[0].squeeze() if fake[0].dim() > 1 else fake[0]\n",
        "            writer.add_audio(f'Fake_{i}', fake_for_tb, epoch, mel_config['sample_rate'])\n",
        "\n",
        "    print(f\"Samples: {sample_dir}\")\n",
        "\n",
        "\n",
        "# 9. TRAINING LOOP\n",
        "\n",
        "\n",
        "print(f\"  –≠–ø–æ—Ö: {training_config['num_epochs']}\")\n",
        "print(f\"  Batch: {training_config['batch_size']} (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π: {training_config['batch_size'] * training_config['accumulation_steps']})\")\n",
        "print(f\"  Steps/epoch: {len(train_loader) * training_config['accumulation_steps']}\")\n",
        "\n",
        "best_g_loss = float('inf')\n",
        "loss_history = []\n",
        "training_start = datetime.now()\n",
        "\n",
        "try:\n",
        "    for epoch in range(1, training_config['num_epochs'] + 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"–≠–ü–û–•–ê {epoch}/{training_config['num_epochs']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        train_losses = train_epoch(epoch)\n",
        "\n",
        "        # TensorBoard logging\n",
        "        writer.add_scalar('Loss/Train_D', train_losses['d'], epoch)\n",
        "        writer.add_scalar('Loss/Train_G', train_losses['g'], epoch)\n",
        "        writer.add_scalar('Loss/Train_Mel', train_losses['g_mel'], epoch)\n",
        "        writer.add_scalar('Params/LR_G', optimizer_g.param_groups[0]['lr'], epoch)\n",
        "        writer.add_scalar('Params/LR_D', optimizer_d.param_groups[0]['lr'], epoch)\n",
        "\n",
        "        print(f\"\\nTRAIN:\")\n",
        "        print(f\"  D: {train_losses['d']:.4f}\")\n",
        "        print(f\"  G: {train_losses['g']:.4f}\")\n",
        "        print(f\"  Mel: {train_losses['g_mel']:.4f}\")\n",
        "\n",
        "        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
        "        if epoch % training_config['save_interval'] == 0:\n",
        "            val_losses = validate(epoch)\n",
        "\n",
        "            writer.add_scalar('Loss/Val_D', val_losses['d'], epoch)\n",
        "            writer.add_scalar('Loss/Val_Mel', val_losses['g_mel'], epoch)\n",
        "\n",
        "            print(f\"\\nVAL:\")\n",
        "            print(f\"  D: {val_losses['d']:.4f}\")\n",
        "            print(f\"  Mel: {val_losses['g_mel']:.4f}\")\n",
        "\n",
        "            if val_losses['g_mel'] < best_g_loss:\n",
        "                best_g_loss = val_losses['g_mel']\n",
        "                torch.save(model.generator.state_dict(), CHECKPOINT_DIR / 'generator_best.pt')\n",
        "                print(f\"  –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å!\")\n",
        "\n",
        "            save_samples(epoch)\n",
        "\n",
        "            # –ü–æ–ª–Ω—ã–π —á–µ–∫–ø–æ–∏–Ω—Ç\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator': model.generator.state_dict(),\n",
        "                'mpd': model.mpd.state_dict(),\n",
        "                'msd': model.msd.state_dict(),\n",
        "                'optimizer_g': optimizer_g.state_dict(),\n",
        "                'optimizer_d': optimizer_d.state_dict(),\n",
        "                'loss_history': loss_history,\n",
        "            }, CHECKPOINT_DIR / f'checkpoint_{epoch:03d}.pt')\n",
        "\n",
        "        scheduler_g.step()\n",
        "        scheduler_d.step()\n",
        "        loss_history.append(train_losses)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\n–û–ë–£–ß–ï–ù–ò–ï –ü–†–ï–†–í–ê–ù–û\")\n",
        "    torch.save(model.generator.state_dict(), CHECKPOINT_DIR / 'generator_interrupted.pt')\n",
        "\n",
        "finally:\n",
        "    training_end = datetime.now()\n",
        "    duration = training_end - training_start\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"–ò–¢–û–ì–ò –û–ë–£–ß–ï–ù–ò–Ø\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration}\")\n",
        "    print(f\"–ó–∞–≤–µ—Ä—à–µ–Ω–æ —ç–ø–æ—Ö: {len(loss_history)}\")\n",
        "    print(f\"–õ—É—á—à–∏–π G Mel Loss: {best_g_loss:.4f}\")\n",
        "\n",
        "    torch.save(model.generator.state_dict(), CHECKPOINT_DIR / 'generator_final.pt')\n",
        "    writer.close()\n",
        "\n",
        "    print(\"\\n–ë–õ–û–ö 4 –ó–ê–í–ï–†–®–ï–ù\")"
      ],
      "metadata": {
        "id": "h8KxEkz5voqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  –û–ë–©–ò–ô –í–´–í–û–î –ü–û –û–ë–£–ß–ï–ù–ò–Æ\n",
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "\n",
        "–ü—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ HiFi-GAN –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ RUSLAN –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–æ **—É—Å–ø–µ—à–Ω—É—é –∏ —Å—Ç–∞–±–∏–ª—å–Ω—É—é —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å** –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ–π —Å–µ—Ç–∏. –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ –≤—ã—Å–æ–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–¥–æ—Ä–æ–≤–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞ –º–µ–∂–¥—É –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–æ–º.\n",
        "\n",
        "**–û—Å–Ω–æ–≤–Ω—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è:**\n",
        "\n",
        "| –ú–µ—Ç—Ä–∏–∫–∞ | –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è | –§–∏–Ω–∞–ª | –£–ª—É—á—à–µ–Ω–∏–µ |\n",
        "|---------|------------------|-------|-----------|\n",
        "| Generator Loss | 52.53 | 13.52 | ‚ñº 74% |\n",
        "| Mel Loss (Train) | 1.105 | 0.281 | ‚ñº 75% |\n",
        "| Mel Loss (Validation) | 0.638 | 0.330 | ‚ñº 48% |\n",
        "| Discriminator Loss | 4.46 | 4.44 | –°—Ç–∞–±–∏–ª–µ–Ω |\n",
        "\n",
        "---\n",
        "\n",
        "### –î–∏–Ω–∞–º–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "#### –§–∞–∑–∞ 1: –ë—ã—Å—Ç—Ä–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è (–ø–µ—Ä–≤—ã–µ 20% –æ–±—É—á–µ–Ω–∏—è)\n",
        "- **Generator Loss** —Å–Ω–∏–∑–∏–ª—Å—è —Å 52.53 –¥–æ 23.38 (‚ñº 55%)\n",
        "- **Mel Loss** —É–ø–∞–ª —Å 1.105 –¥–æ 0.500 (‚ñº 55%)\n",
        "- –ú–æ–¥–µ–ª—å –±—ã—Å—Ç—Ä–æ –æ—Å–≤–æ–∏–ª–∞ –±–∞–∑–æ–≤–æ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º\n",
        "- –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω—è–ª —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (D Loss ‚âà 4.44)\n",
        "\n",
        "#### –§–∞–∑–∞ 2: –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ (20-100% –æ–±—É—á–µ–Ω–∏—è)\n",
        "- **Generator Loss** –ø—Ä–æ–¥–æ–ª–∂–∏–ª —Å–Ω–∏–∂–µ–Ω–∏–µ –¥–æ 13.52 (‚ñº –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ 42%)\n",
        "- **Mel Loss** –¥–æ—Å—Ç–∏–≥ 0.281 (‚ñº –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ 44%)\n",
        "- –ó–∞–º–µ–¥–ª–µ–Ω–∏–µ —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ –∫ –æ–ø—Ç–∏–º—É–º—É\n",
        "- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (train-val —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ)\n",
        "\n",
        "#### –§–∞–∑–∞ 3: –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
        "- **–õ—É—á—à–∏–π –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π Mel Loss**: 0.3303\n",
        "- –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ö–æ—Ä–æ—à–µ–µ –æ–±–æ–±—â–µ–Ω–∏–µ\n",
        "- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ä–µ–∑–∫–∏—Ö —Å–∫–∞—á–∫–æ–≤ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É–µ—Ç –æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –±–∞–ª–∞–Ω—Å–µ GAN\n",
        "\n",
        "---\n",
        "\n",
        "### –ö–ª—é—á–µ–≤—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è\n",
        "\n",
        "#### 1. –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞\n",
        "Discriminator Loss –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–µ—Ä–∂–∞–ª—Å—è –≤ —É–∑–∫–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ **4.44-4.46**, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –∏–¥–µ–∞–ª—å–Ω—ã–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º –¥–ª—è GAN. –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç:\n",
        "- –î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω—è–ª —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å —Ä–∞–∑–ª–∏—á–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ\n",
        "- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ \"–∑–∞—Å—ã–ø–∞–Ω–∏—è\" –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (mode collapse)\n",
        "- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "#### 2. –ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n",
        "Mel Loss —Å–Ω–∏–∑–∏–ª—Å—è —Å **1.105 –¥–æ 0.281** (—É–ª—É—á—à–µ–Ω–∏–µ –≤ **3.9 —Ä–∞–∑–∞**). –ù–∏–∑–∫–∏–π Mel Loss –∫–æ—Ä—Ä–µ–ª–∏—Ä—É–µ—Ç —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ä–µ—á–∏, —Ç–∞–∫ –∫–∞–∫ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Ç—Ä–∞–∂–∞–µ—Ç –≤–æ—Å–ø—Ä–∏—è—Ç–∏–µ –∑–≤—É–∫–∞ —á–µ–ª–æ–≤–µ–∫–æ–º.\n",
        "\n",
        "#### 3. –û–±–æ–±—â–∞—é—â–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å\n",
        "–†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É train –∏ validation Mel Loss —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤—Å–µ–≥–æ **0.049** (0.281 vs 0.330), —á—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞:\n",
        "- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è\n",
        "- –•–æ—Ä–æ—à—É—é –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ\n",
        "- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\n",
        "\n",
        "#### 4. –°–∫–æ—Ä–æ—Å—Ç—å —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏\n",
        "–ù–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–æ –≤ –ø–µ—Ä–≤–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ –ø—Ä–æ—Ü–µ—Å—Å–∞, –≥–¥–µ –º–æ–¥–µ–ª—å –æ—Å–≤–æ–∏–ª–∞ **75%** –æ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞. –í—Ç–æ—Ä–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ –æ–±—É—á–µ–Ω–∏—è –æ–±–µ—Å–ø–µ—á–∏–ª–∞ —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏—é.\n",
        "\n",
        "---\n",
        "\n",
        "### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏\n",
        "\n",
        "| –ê—Å–ø–µ–∫—Ç | –û–∂–∏–¥–∞–Ω–∏–µ | –†–µ–∞–ª—å–Ω–æ—Å—Ç—å |\n",
        "|--------|----------|------------|\n",
        "| –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å D Loss | –ö–æ–ª–µ–±–∞–Ω–∏—è 3.5-4.5 | –°—Ç–∞–±–∏–ª—å–Ω–æ 4.44 |  \n",
        "| –°–Ω–∏–∂–µ–Ω–∏–µ Mel Loss | 80-90% | 75% |  \n",
        "| Train-Val —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ | < 20% | 15% |\n",
        "| –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ mode collapse | –ö—Ä–∏—Ç–∏—á–Ω–æ | –î–æ—Å—Ç–∏–≥–Ω—É—Ç–æ |\n",
        "\n",
        "---\n",
        "\n",
        "### –í—ã–≤–æ–¥—ã –æ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏\n",
        "\n",
        "1. **–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –Ω–∞—É—á–∏–ª—Å—è** –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã —Å –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é (Mel Loss 0.28)\n",
        "2. **–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä —Å–æ—Ö—Ä–∞–Ω–∏–ª** —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "3. **–°–∏—Å—Ç–µ–º–∞ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∞** ‚Äî –Ω–∏ –æ–¥–∏–Ω –∏–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–µ –¥–æ–º–∏–Ω–∏—Ä—É–µ—Ç\n",
        "4. **–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é** –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ –∏–∑ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º\n",
        "\n",
        "---\n",
        "\n",
        "### –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –∑–Ω–∞—á–∏–º–æ—Å—Ç—å\n",
        "\n",
        "–î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∑–≤–æ–ª—è—é—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è:\n",
        "\n",
        "| –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |\n",
        "|------------|----------|\n",
        "|  **–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏** | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞—É–¥–∏–æ –∏–∑ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ |\n",
        "|  **–†–µ—Å–µ–º–ø–ª–∏–Ω–≥** | –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ –º–µ–ª-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è |\n",
        "|  **–¢—Ä–∞–Ω—Å—Ñ–µ—Ä –æ–±—É—á–µ–Ω–∏—è** | –ê–¥–∞–ø—Ç–∞—Ü–∏—è –¥–ª—è –¥—Ä—É–≥–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏–ª–∏ —è–∑—ã–∫–æ–≤ |\n",
        "|  **–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è** | –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ |\n",
        "\n",
        "---\n",
        "\n",
        "### –ó–∞–∫–ª—é—á–µ–Ω–∏–µ\n",
        "\n",
        "–û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ **—É—Å–ø–µ—à–Ω–æ –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ**, –±–µ–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –¥–ª—è GAN –ø—Ä–æ–±–ª–µ–º mode collapse –∏–ª–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏. –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–ª–∞ —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∑–¥–æ—Ä–æ–≤–æ–≥–æ —Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ –±–∞–ª–∞–Ω—Å–∞. –ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ø–æ—Å–æ–±–µ–Ω —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤—ã—Å–æ–∫–æ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∞—É–¥–∏–æ—Å–∏–≥–Ω–∞–ª—ã, –∞ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä –æ—Å—Ç–∞–µ—Ç—Å—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∫—Ä–∏—Ç–∏–∫–æ–º –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞."
      ],
      "metadata": {
        "id": "8ROQfEsR4Y40"
      }
    }
  ]
}